# -*- coding: utf-8 -*-
"""Untitled14.ipynb

Automatically generated by Colaboratory.

Original file is located at
	https://colab.research.google.com/drive/18Y768EeE-EXD5I59vMRFw3VDENFBt9re
"""

import numpy as np
import math
import os
import pandas as pd
import glob
import tensorflow as tf
from tensorflow import keras
from keras import layers
from keras.layers import Input, TimeDistributed, LSTM, Dense, Dropout, Bidirectional, GRU, Normalization, SpatialDropout1D, CuDNNLSTM, Conv1D, MaxPooling2D, Flatten, Attention
from keras.models import Model, load_model
from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad, Adadelta, Adamax
from keras.regularizers import l1_l2, l1, l2

time_steps = 15 # Frames extracted from the video
aud_ft = 68 # Number of Audio features extracted from each non overlapping frame 

class AdversarialDebiasing(keras.Model):
	def __init__(self, classifier, adversary, alpha, c_loss, a_loss, debias=True):
		super(AdversarialDebiasing, self).__init__()
		self.classifier = classifier
		self.adversary = adversary
		self.c_loss = c_loss #metric for classifier
		self.a_loss = a_loss #metric for adversaary
		self.protect_loss_weight = alpha
		self.debias = debias
		
	@property
	def metrics(self):
		return [self.c_loss, self.a_loss]


	def compile(self, optimizer,c_loss_fn, a_loss_fn):
		super(AdversarialDebiasing, self).compile()
		self.c_optimizer = optimizer[0]
		self.a_optimizer = optimizer[1]
		self.c_loss_fn = c_loss_fn
		self.a_loss_fn = a_loss_fn

		
	def call(self, data):
		x = data
		y = self.classifier(x)
		z = self.adversary(y)
		return [y,z]
		
		
	def train_step(self, data):
		
		x, y = data
#         print(y)
		e_g = y[:, 5:]
		y = y[:, 0:5]
		
#         print(self.epoch)

		with tf.GradientTape() as tape:
			c_predictions = self.classifier(x)
			c_loss = self.c_loss_fn(y, c_predictions)

			
		c_grads = tape.gradient(c_loss, self.classifier.trainable_weights)

		
		with tf.GradientTape() as tape:
			c_predictions = self.classifier(x)
			a_predictions = self.adversary(c_predictions)
			a_loss = self.a_loss_fn(e_g, a_predictions)
			
		
		a_grads = tape.gradient(a_loss, self.classifier.trainable_weights) #projection
		
		
		with tf.GradientTape() as tape:
			c_predictions = self.classifier(x)
			a_predictions = self.adversary(c_predictions)
			a_loss = self.a_loss_fn(e_g, a_predictions)
			
		a_grads_own = tape.gradient(a_loss, self.adversary.trainable_weights)

		if self.debias:
			protect_grad = {v.name: g for (g, v) in zip(a_grads, self.classifier.trainable_weights)}
			pred_grad = [] #classifier update function
		
			for (g, v) in zip(c_grads, self.classifier.trainable_weights):
				unit_protect = protect_grad[v.name] / (tf.norm(protect_grad[v.name]) + np.finfo(np.float32).tiny)
				g -= tf.reduce_sum(g * unit_protect) * unit_protect # g- projection
				g -= self.protect_loss_weight * protect_grad[v.name] # g - projection - alpha*adv grad
#                 g -= math.sqrt(self.protect_loss_weight) * protect_grad[v.name] # g - projection - alpha*adv grad
				pred_grad.append((g, v))
				 
			self.c_optimizer.apply_gradients(pred_grad)
		
		else:
			self.c_optimizer.apply_gradients(zip(c_grads, self.classifier.trainable_weights))
			
		
		self.a_optimizer.apply_gradients(zip(a_grads_own, self.adversary.trainable_weights))
		
		self.c_loss.update_state(y,c_predictions)
		self.a_loss.update_state(e_g, a_predictions)
		
#         self.epoch+=1
		
		return {m.name: m.result() for m in self.metrics}
	
	
	
	def test_step(self, data):
		
		x, y = data
		
		e_g = y[:, 5:]
		y = y[:, 0:5]

		c_predictions = self.classifier(x)
		c_loss = self.c_loss_fn(y, c_predictions)
		a_predictions = self.adversary(c_predictions)
		a_loss = self.a_loss_fn(e_g, a_predictions)
			
		
		self.c_loss.update_state(y,c_predictions)
		self.a_loss.update_state(e_g, a_predictions)
		
		return {m.name: m.result() for m in self.metrics}


classifier = keras.Sequential(
	[
		Input(shape=(time_steps, aud_ft)),
		SpatialDropout1D(0.3),
		LSTM(20, return_sequences=False,dropout=0.2,recurrent_dropout=0.2, kernel_regularizer=l1()),
		Dense(5,activation='sigmoid'),
	],
	name="classifier",
)

adversary = keras.Sequential(
		[
			keras.Input(shape=(5,)),
			Dense(200, activation='relu', name="dense"),
			Dense(2, activation='sigmoid', name="output"),
		],
		name="adversary",
	)


def ocean_predict(audio_feature_path):

	model = AdversarialDebiasing(classifier, adversary, 1,
								   keras.metrics.MeanAbsoluteError(name="c_loss"), 
								   keras.metrics.BinaryCrossentropy(name="a_loss"),
								   debias=True,
								  )


	model.compile(
		optimizer=[keras.optimizers.RMSprop(learning_rate=0.001, decay = 0.0005),keras.optimizers.RMSprop(learning_rate=0.001),],
		c_loss_fn = keras.losses.MeanAbsoluteError(),
		a_loss_fn = keras.losses.BinaryCrossentropy(),
	)

	model.built=True

	model.load_weights("D:\\Sarika\\PersonalityPredictionFromAVI\\models\\audio 22_Feb\\audio_rmsprop_debias_true.h5")
	# print(audio_feature_path)
	data=pd.read_csv(audio_feature_path)
	data1=data.to_numpy()
	data1.shape

	data2 = np.empty((0,time_steps,aud_ft))
	if data1.shape[0]<15:
		rows = 15 - data1.shape[0]
		zeros = np.zeros((rows, 68))
		data1 = np.vstack((data1,zeros))

	data1 = np.vstack((data2,data1[np.newaxis,...]))

	data1.shape

	return model.predict(data1)

